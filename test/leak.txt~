有1亿个不重复的64位的01字符串，任意给出一个64位的01字符串f，如何快速从中找出与f汉明距离小于3的字符串？
 
大规模网页的近似查重
主要翻译自WWW07的Detecting Near-Duplicates for Web Crawling 
WWW上存在大量内容近似相同的网页，对搜索引擎而言，去除近似相同的网页可以提高检索效率、降低存储开销。
当爬虫在抓取网页时必须很快能在海量文本集中快速找出是否有重复的网页。
 
论文主要2个贡献：
1.      展示了simhash可以用以海量文本查重
2.      提出了一个在实际应用中可行的算法。
 
两篇文本相似度普遍的定义是比较向量化之后两个词袋中词的交集程度，有cosine,jaccard等等
如果直接使用这种计算方式，时间空间复杂度都太高，因此有了simhash这种降维技术，
但是如何从传统的向量相似度能用simhash来近似，论文没提，应该是有很长一段推导要走的。
Simhash算法
一篇文本提取出内容以后，经过基本的预处理，比如去除停词，词根还原，甚至chunking，最后可以得到一个向量。
对每一个term进行hash算法转换，得到长度f位的hash码，每一位上1-0值进行正负权值转换，例如f1位是1时，权值设为 +weight, fk位为0时，权值设为-weight。
讲文本中所有的term转换出的weight向量按f对应位累加最后得到一个f位的权值数组，位为正的置1，位为负的置0，那么文本就转变成一个f位的新1-0数组，也就是一个新的hash码。

 
 
Simhash具有两个“冲突的性质”：
1.      它是一个hash方法
2.      相似的文本具有相似的hash值，如果两个文本的simhash越接近，也就是汉明距离越小，文本就越相似。
 
 
因此海量文本中查重的任务转换位如何在海量simhash中快速确定是否存在汉明距离小的指纹。
也就是：在n个f-bit的指纹中，查询汉明距离小于k的指纹。
 
在文章的实验中（见最后），simhash采用64位的哈希函数。在80亿网页规模下汉明距离=3刚好合适。
因此任务的f-bit=64 , k=3 , n= 8*10^11
 
 
任务清晰，首先看一下两种很直观的方法：
1.      对输入指纹，枚举出所有汉明距离小于3的simhash指纹，对每个指纹在80亿排序指纹中查询。
（这种方法需要进行C（64，3）=41664次的simhash指纹，再为每个进行一次查询）
2.     输入指纹不变，对应集合相应位置变。也就是集合上任意3位组合的位置进行变化，实际上就是提前准备41664个排序可能，需要庞大的空间。输入在这群集合并行去搜....
